{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2720e5b-8393-494e-b1ee-143b9d95be28",
   "metadata": {},
   "source": [
    "# Experiment: Generalist vs Specialists - Naive Bayes, SVM, Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61e132b3-ad15-4461-90a2-fa74d35cd467",
   "metadata": {},
   "outputs": [],
   "source": [
    "from echr import *\n",
    "from nb_tfidf import *\n",
    "from bert import *\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from csv import DictWriter\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.base import clone\n",
    "import gc\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17dc7bc6-412d-47a3-9aa2-41e7fdb98380",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'datasets/Medvedeva/'\n",
    "json_path = 'datasets/echrod/cases.json'\n",
    "part = 'facts'\n",
    "article = '6'\n",
    "balance = True\n",
    "best_alpha = 5\n",
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c05267d9-d20f-4613-9f04-44ac62caa6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(model, df_train, df_test):\n",
    "       \n",
    "    # Balance the training data\n",
    "    df_train = balance_dataset(df_train) \n",
    "\n",
    "    # Split the features and label\n",
    "    X_train = df_train['text'].to_numpy()\n",
    "    y_train = df_train['violation'].to_numpy()\n",
    "    X_test = df_test['text'].to_numpy()\n",
    "    y_test = df_test['violation'].to_numpy()\n",
    "   \n",
    "    # Preprocess\n",
    "    X_train_preprocessed = np.array([text_preprocessing(text) for text in X_train])\n",
    "    X_test_preprocessed = np.array([text_preprocessing(text) for text in X_test])\n",
    "\n",
    "    # Calculate TF-IDF\n",
    "    tf_idf = TfidfVectorizer(ngram_range=(1, 3),\n",
    "                             binary=True,\n",
    "                             smooth_idf=False)\n",
    "    X_train_tfidf = tf_idf.fit_transform(X_train_preprocessed)\n",
    "    X_test_tfidf = tf_idf.transform(X_test_preprocessed)\n",
    "\n",
    "    # Train model\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "    # Test model\n",
    "    preds = model.predict(X_test_tfidf)\n",
    "\n",
    "    full_preds = {}\n",
    "    full_preds['final_pred'] = preds\n",
    "    full_preds['true_pred'] = y_test\n",
    "\n",
    "    return return_metrics(preds, y_test), pd.DataFrame.from_dict(full_preds) #acc, mcc, f1\n",
    "\n",
    "\n",
    "def train_test_ensemble(model, df_train_sets, df_test):\n",
    "    \n",
    "    full_preds = {}\n",
    "    all_preds = []\n",
    "    \n",
    "    for art, df_train in tqdm(df_train_sets.items()):\n",
    "        \n",
    "        c_model = clone(model)\n",
    "        \n",
    "        if type(df_train) == str:\n",
    "            if debug: print('reading data')\n",
    "            df_train = pd.read_csv(df_train).dropna()\n",
    "            if debug: print(art, len(df_train))\n",
    "        \n",
    "        if debug: print('balancing data')\n",
    "        # Balance the training data\n",
    "        df_train = balance_dataset(df_train)\n",
    "        if debug: print('after balance, train_df length is', len(df_train))\n",
    "\n",
    "\n",
    "        if debug: print('Splitting data')\n",
    "        # Split the features and label\n",
    "        X_train = df_train['text'].to_numpy()\n",
    "        y_train = df_train['violation'].to_numpy()\n",
    "        if debug: print('Splitting test data')\n",
    "        X_test = df_test['text'].to_numpy()\n",
    "        y_test = df_test['violation'].to_numpy()\n",
    "        del df_train\n",
    "        \n",
    "        if debug: print('Preprocessing data, x_train has length', len(X_train))\n",
    "        # Preprocess\n",
    "        X_train_preprocessed = np.array([text_preprocessing(text) for text in X_train])\n",
    "        if debug: print('Preprocessing test data, x_test has length', len(X_train))\n",
    "        X_test_preprocessed = np.array([text_preprocessing(text) for text in X_test])\n",
    "        del X_train\n",
    "        del X_test\n",
    "\n",
    "        # Calculate TF-IDF\n",
    "        if debug: print('TFIDF')\n",
    "        tf_idf = TfidfVectorizer(ngram_range=(1, 3),\n",
    "                                 binary=True,\n",
    "                                 smooth_idf=False)\n",
    "        X_train_tfidf = tf_idf.fit_transform(X_train_preprocessed)\n",
    "        X_test_tfidf = tf_idf.transform(X_test_preprocessed)\n",
    "        del X_train_preprocessed\n",
    "        del X_test_preprocessed\n",
    "\n",
    "        if debug: print('Training model')\n",
    "       # Train model\n",
    "        c_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "        # Test model\n",
    "        preds = c_model.predict(X_test_tfidf)\n",
    "        \n",
    "        full_preds[art] = preds\n",
    "        \n",
    "        # OR layer: if any model predicts violation the ensemble prediction is violation\n",
    "        if len(all_preds) == 0:\n",
    "            all_preds = preds\n",
    "        else:\n",
    "            for idx, pred in enumerate(preds):\n",
    "                all_preds[idx] = max(pred, all_preds[idx])\n",
    "        if debug: print('Finished round')\n",
    "        \n",
    "        # Cleanup to reduce memory\n",
    "        del X_train_tfidf\n",
    "        del X_test_tfidf\n",
    "        del c_model\n",
    "        del y_train\n",
    "        del preds\n",
    "        gc.collect()\n",
    "\n",
    "    full_preds['final_pred'] = all_preds\n",
    "    full_preds['true_pred'] = y_test\n",
    "    \n",
    "        \n",
    "    return return_metrics(all_preds, y_test), pd.DataFrame.from_dict(full_preds) #acc, mcc, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "653b0ddc-dc1c-4b61-aa98-b2a0206d2a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 1995\n",
    "random_states = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "def generate_ensemble_dataset(path, random_state, write=False):\n",
    "\n",
    "    article_numbers = ['2', '3', '5', '6', '8', '10', '11', '13', '14']\n",
    "    datasets = {art: create_dataset(path, art, part) for art in tqdm(article_numbers)}\n",
    "    df_all = create_dataset(json_path, 'All', part)\n",
    "\n",
    "    # Individual training datasets (for each article)\n",
    "    train_dbs = {}\n",
    "    \n",
    "    # Individual training datasets including irrelevant cases (with non-violation label for that case)\n",
    "    improved_train_dbs = {}\n",
    "    \n",
    "    # General test dataset (binary)\n",
    "    test_db = [] \n",
    "    test_size = 0.1\n",
    "\n",
    "    # Remove 10% of all the datasets\n",
    "    for art, db in datasets.items():\n",
    "        db['article'] = art\n",
    "        train, test = train_test_split(db, test_size=0.1, random_state=random_state, stratify=db['violation'])\n",
    "        train_dbs[art] = train \n",
    "        test_db.append(test)\n",
    "\n",
    "    # All individual 10% test cases form the big test dataset\n",
    "    test_db = pd.concat(test_db)\n",
    "\n",
    "    # The general test set has binary labels\n",
    "    test_general = df_all[df_all.id.isin(test_db['id'])]\n",
    "\n",
    "    # General training dataset (binary)\n",
    "    # Remove all test instances from the general training dataset\n",
    "    train_general = df_all[~df_all.id.isin(test_db['id'])]\n",
    "    \n",
    "    # improved ensemble datasets\n",
    "    for art, db in train_dbs.items():\n",
    "        \n",
    "        # All cases that were not in the article db\n",
    "        additional_cases = df_all[~df_all.id.isin(db['id'])]\n",
    "        additional_cases['violation'] = 0\n",
    "        additional_cases['article'] = 999 # add 999 to symbolise that it is another article\n",
    "        \n",
    "        # split violation and non violation of the article db\n",
    "        violation_cases = db[db['violation']==1]\n",
    "        nonviolation_cases = db[db['violation']==0]\n",
    "        violation_cases = violation_cases.sample(n=min(2500, len(violation_cases))) # take a sample to reduce space\n",
    "        \n",
    "        # There are usually less nonviolation cases. Add additional cases from other articles such that the number of non-violation cases\n",
    "        # is equal to the amount of violation cases, making a larger, balanced dataset. If there are more non-violation cases, add nothing.\n",
    "        additional_cases = additional_cases.sample(n=max(0, len(violation_cases)-len(nonviolation_cases)))\n",
    "        \n",
    "        # Add the three datasets together\n",
    "        improved_train_dbs[art] = pd.concat([violation_cases, nonviolation_cases, additional_cases])\n",
    "        \n",
    "        if debug: print(art, len(db), len(violation_cases),  len(nonviolation_cases), len(additional_cases), len(improved_train_dbs[art]))\n",
    "        del additional_cases\n",
    "        del violation_cases\n",
    "        del nonviolation_cases\n",
    "        \n",
    "    # Write all datasets to csv to reduce memory\n",
    "    if write:\n",
    "        balance_dataset(train_general).to_csv('results/ensemble/temp/train_general.csv')\n",
    "        test_general.to_csv('results/ensemble/temp/test_general.csv')\n",
    "\n",
    "        for art, db in train_dbs.items():\n",
    "            balance_dataset(db).to_csv('results/ensemble/temp/train_dbs'+str(art)+'.csv')\n",
    "\n",
    "        for art, db in improved_train_dbs.items():\n",
    "            balance_dataset(db).to_csv('results/ensemble/temp/improved_train_dbs'+str(art)+'.csv')\n",
    "\n",
    "        del train_dbs\n",
    "        del improved_train_dbs\n",
    "        del train_general\n",
    "        del test_general\n",
    "        gc.collect()\n",
    "\n",
    "        return None, None, None, None\n",
    "    \n",
    "    return train_dbs, improved_train_dbs, train_general, test_general\n",
    "\n",
    "def read_ensemble_dataset(db_name):\n",
    "    if db_name == 'train_general':\n",
    "        return pd.read_csv('results/ensemble/temp/train_general.csv').dropna()\n",
    "    if db_name == 'test_general':\n",
    "        return pd.read_csv('results/ensemble/temp/test_general.csv').dropna()\n",
    "    if db_name == 'train_dbs':\n",
    "        return {art:'results/ensemble/temp/train_dbs'+str(art)+'.csv'\n",
    "                for art in ['2', '3', '5', '6', '8', '10', '11', '13', '14']}\n",
    "    if db_name == 'improved_train_dbs':\n",
    "        return {art:'results/ensemble/temp/improved_train_dbs'+str(art)+'.csv'\n",
    "                for art in ['2', '3', '5', '6', '8', '10', '11', '13', '14']}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ef4aa56-d176-4aad-b407-4843802ed972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(model, model_name, random_state, provided_dbs=None):\n",
    "    if not provided_dbs:\n",
    "        print('\\tNo provided data, reading from files')\n",
    "        train_dbs, improved_train_dbs, train_general, test_general = generate_ensemble_dataset(json_path, random_state)\n",
    "        train_dbs, improved_train_dbs, train_general, test_general = read_ensemble_dataset()\n",
    "    else:\n",
    "        train_dbs = provided_dbs['train_dbs']\n",
    "        improved_train_dbs = provided_dbs['improved_train_dbs']\n",
    "        train_general = provided_dbs['train_general']\n",
    "        test_general = provided_dbs['test_general']\n",
    "\n",
    "    # General\n",
    "    print('\\tTraining general classifier')\n",
    "    (acc_g, mcc_g, f1_g), full_preds = train_test(clone(model), read_ensemble_dataset('train_general'), read_ensemble_dataset('test_general'))\n",
    "    full_preds.to_csv('results/ensemble/full_preds/'+model_name+'/general/full_preds_general_'+str(random_state)+'.csv')\n",
    "\n",
    "#     #ensemble\n",
    "    print('\\tTraining ensemble')\n",
    "    (acc_e, mcc_e, f1_e), full_preds = train_test_ensemble(clone(model), read_ensemble_dataset('train_dbs'), read_ensemble_dataset('test_general'))\n",
    "    full_preds.to_csv('results/ensemble/full_preds/'+model_name+'/ensemble/full_preds_ensemble_'+str(random_state)+'.csv')\n",
    "    \n",
    "    #improved ensemble\n",
    "    print('\\tTraining improved ensemble')\n",
    "    (acc_e2, mcc_e2, f1_e2), full_preds = train_test_ensemble(clone(model), read_ensemble_dataset('improved_train_dbs'), read_ensemble_dataset('test_general'))\n",
    "    full_preds.to_csv('results/ensemble/full_preds/'+model_name+'/improved_ensemble/full_preds_improved_ensemble_'+str(random_state)+'.csv')\n",
    "    \n",
    "    print('\\tWriting data')\n",
    "    field_names = ['model', 'random_state', 'accuracy_general', 'MCC_general', 'F1_general', \n",
    "                   'accuracy_ensemble', 'MCC_ensemble', 'F1_ensemble', \n",
    "                   'accuracy_improved_ensemble', 'MCC_improved_ensemble', 'F1_improved_ensemble', \n",
    "                   'alpha',  'training_size', 'test_size', 'train_distribution', 'test_distribution']\n",
    "    \n",
    "    train_general = read_ensemble_dataset('train_general')\n",
    "    test_general = read_ensemble_dataset('test_general')\n",
    "    \n",
    "    dct = {\n",
    "        'model': model_name,\n",
    "        'random_state': random_state,\n",
    "        'accuracy_general': acc_g,\n",
    "        'MCC_general': mcc_g,\n",
    "        'F1_general': f1_g,\n",
    "        'accuracy_ensemble': acc_e,\n",
    "        'MCC_ensemble': mcc_e,\n",
    "        'F1_ensemble': f1_e,\n",
    "        'accuracy_improved_ensemble': acc_e2,\n",
    "        'MCC_improved_ensemble': mcc_e2,\n",
    "        'F1_improved_ensemble': f1_e2,\n",
    "        'alpha': best_alpha,\n",
    "        'training_size': len(train_general),\n",
    "        'test_size': len(test_general),\n",
    "        'train_distribution': round(train_general['violation'].mean()*100,2),\n",
    "        'test_distribution': round(test_general['violation'].mean()*100,2)\n",
    "         }\n",
    "    \n",
    "    filename = 'results/ensemble/ensemble_general.csv'\n",
    "    file_exists = os.path.isfile(filename)\n",
    "    with open(filename, 'a') as f_object:\n",
    "        dictwriter_object = DictWriter(f_object, fieldnames=field_names)\n",
    "        if not file_exists:\n",
    "            dictwriter_object.writeheader()  # file doesn't exist yet, write a header\n",
    "        dictwriter_object.writerow(dct)\n",
    "        f_object.close()\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e16c80-2e0e-4d16-9909-7682abc4d5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "provided_dbs = None\n",
    "for random_state in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]:\n",
    "    print('Random_state:', random_state)\n",
    "    \n",
    "    # Generate and write datasets\n",
    "    _, _, _, _ = generate_ensemble_dataset(json_path, random_state, write=True)\n",
    "    provided_dbs = None    \n",
    "\n",
    "    # Run experiment for each model\n",
    "    print('NB')\n",
    "    run_experiment(MultinomialNB(alpha=best_alpha), 'NB', random_state, provided_dbs=provided_dbs)\n",
    "    print('SVM')\n",
    "    run_experiment(SGDClassifier(n_jobs=1, alpha=0.0001, max_iter=100, penalty='l2'), 'SVM', random_state, provided_dbs=provided_dbs)\n",
    "    print('RF')\n",
    "    run_experiment(RandomForestClassifier(n_jobs=-1, bootstrap=False,  max_depth=100.0, max_features='auto',  min_samples_leaf=2,  min_samples_split=10,  n_estimators=2000), 'RF', random_state, provided_dbs=provided_dbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592cf39b-6e89-4a0a-95dc-e4a9ca3d6dbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
