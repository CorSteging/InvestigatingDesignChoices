{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4fb1492-ce89-4b98-a5c5-949df4b93e66",
   "metadata": {},
   "source": [
    "# Experiment: Generalist vs Specialists - BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61e132b3-ad15-4461-90a2-fa74d35cd467",
   "metadata": {},
   "outputs": [],
   "source": [
    "from echr import *\n",
    "from nb_tfidf import *\n",
    "from bert import *\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from csv import DictWriter\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.base import clone\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "import gc\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17dc7bc6-412d-47a3-9aa2-41e7fdb98380",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'datasets/Medvedeva/'\n",
    "json_path = 'datasets/echrod/cases.json'\n",
    "part = 'facts'\n",
    "article = '6'\n",
    "balance = True\n",
    "batch_size = 16\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac8e31b7-68e0-41bf-8e89-a193228c57a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "Device name: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c05267d9-d20f-4613-9f04-44ac62caa6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(model, df_train, df_test):\n",
    "    \n",
    "    def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False, debug=0):\n",
    "        \"\"\"Train the BertClassifier model.\n",
    "        \"\"\"\n",
    "\n",
    "        # Specify loss function\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Start training loop\n",
    "        if debug: print(\"Start training...\\n\")\n",
    "        for epoch_i in range(epochs):\n",
    "            # =======================================\n",
    "            #               Training\n",
    "            # =======================================\n",
    "            # Print the header of the result table\n",
    "            if debug: print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
    "            if debug: print(\"-\"*70)\n",
    "\n",
    "            # Measure the elapsed time of each epoch\n",
    "            t0_epoch, t0_batch = time.time(), time.time()\n",
    "\n",
    "            # Reset tracking variables at the beginning of each epoch\n",
    "            total_loss, batch_loss, batch_counts = 0, 0, 0\n",
    "\n",
    "            # Put the model into the training mode\n",
    "            model.train()\n",
    "\n",
    "            # For each batch of training data...\n",
    "            for step, batch in enumerate(train_dataloader):\n",
    "                batch_counts +=1\n",
    "                # Load batch to GPU\n",
    "                b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "                # Zero out any previously calculated gradients\n",
    "                model.zero_grad()\n",
    "\n",
    "                # Perform a forward pass. This will return logits.\n",
    "                logits = model(b_input_ids, b_attn_mask)\n",
    "\n",
    "                # Compute loss and accumulate the loss values\n",
    "                loss = loss_fn(logits, b_labels)\n",
    "                batch_loss += loss.item()\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                # Perform a backward pass to calculate gradients\n",
    "                loss.backward()\n",
    "\n",
    "                # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "                # Update parameters and the learning rate\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "\n",
    "                # Print the loss values and time elapsed for every 20 batches\n",
    "                if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
    "                    # Calculate time elapsed for 20 batches\n",
    "                    time_elapsed = time.time() - t0_batch\n",
    "\n",
    "                    # Print training results\n",
    "                    if debug: print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
    "\n",
    "                    # Reset batch tracking variables\n",
    "                    batch_loss, batch_counts = 0, 0\n",
    "                    t0_batch = time.time()\n",
    "\n",
    "            # Calculate the average loss over the entire training data\n",
    "            avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "            if debug: print(\"-\"*70)\n",
    "            # =======================================\n",
    "            #               Evaluation\n",
    "            # =======================================\n",
    "            if evaluation == True:\n",
    "                # After the completion of each training epoch, measure the model's performance\n",
    "                # on our validation set.\n",
    "                val_loss, val_accuracy = evaluate(model, val_dataloader, device)\n",
    "\n",
    "                # Print performance over the entire training data\n",
    "                time_elapsed = time.time() - t0_epoch\n",
    "\n",
    "                if debug: print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
    "                if debug: print(\"-\"*70)\n",
    "            if debug: print(\"\\n\")\n",
    "        if debug: print(\"Training complete!\")\n",
    "\n",
    "    # Balance the training data\n",
    "    df_train = balance_dataset(df_train) \n",
    "\n",
    "    # Split the features and label\n",
    "    X_train = df_train['text'].to_numpy()\n",
    "    y_train = df_train['violation'].to_numpy()\n",
    "    X_test = df_test['text'].to_numpy()\n",
    "    y_test = df_test['violation'].to_numpy()\n",
    "        \n",
    "    # Train and test the model\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "    train_inputs, train_masks = preprocessing_for_bert(X_train, tokenizer)\n",
    "\n",
    "    set_seed(42)\n",
    "\n",
    "    # Train\n",
    "    train_labels = torch.tensor(y_train)\n",
    "    train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "    bert_classifier, optimizer, scheduler = initialize_model(device, train_dataloader, epochs=epochs)\n",
    "    for _ in tqdm([None]):\n",
    "        train(bert_classifier, train_dataloader, epochs=epochs)\n",
    "\n",
    "    # Test\n",
    "    test_inputs, test_masks = preprocessing_for_bert(X_test, tokenizer)\n",
    "    test_dataset = TensorDataset(test_inputs, test_masks)\n",
    "    test_sampler = SequentialSampler(test_dataset)\n",
    "    test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=batch_size)\n",
    "    probs = bert_predict(bert_classifier, test_dataloader)\n",
    "\n",
    "    # Get predictions from the probabilities\n",
    "    threshold = 0.5\n",
    "    preds = np.where(probs[:, 1] >= 0.5, 1, 0)\n",
    "    return return_metrics(preds, y_test, show=False) #acc, mcc, f1\n",
    "\n",
    "\n",
    "def train_test_ensemble(model, df_train_sets, df_test):\n",
    "    \n",
    "    def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False, debug=0):\n",
    "        \"\"\"Train the BertClassifier model.\n",
    "        \"\"\"\n",
    "\n",
    "        # Specify loss function\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Start training loop\n",
    "        if debug: print(\"Start training...\\n\")\n",
    "        for epoch_i in range(epochs):\n",
    "            # =======================================\n",
    "            #               Training\n",
    "            # =======================================\n",
    "            # Print the header of the result table\n",
    "            if debug: print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
    "            if debug: print(\"-\"*70)\n",
    "\n",
    "            # Measure the elapsed time of each epoch\n",
    "            t0_epoch, t0_batch = time.time(), time.time()\n",
    "\n",
    "            # Reset tracking variables at the beginning of each epoch\n",
    "            total_loss, batch_loss, batch_counts = 0, 0, 0\n",
    "\n",
    "            # Put the model into the training mode\n",
    "            model.train()\n",
    "\n",
    "            # For each batch of training data...\n",
    "            for step, batch in enumerate(train_dataloader):\n",
    "                batch_counts +=1\n",
    "                # Load batch to GPU\n",
    "                b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "                # Zero out any previously calculated gradients\n",
    "                model.zero_grad()\n",
    "\n",
    "                # Perform a forward pass. This will return logits.\n",
    "                logits = model(b_input_ids, b_attn_mask)\n",
    "\n",
    "                # Compute loss and accumulate the loss values\n",
    "                loss = loss_fn(logits, b_labels)\n",
    "                batch_loss += loss.item()\n",
    "                total_loss += loss.item()\n",
    "\n",
    "                # Perform a backward pass to calculate gradients\n",
    "                loss.backward()\n",
    "\n",
    "                # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "                # Update parameters and the learning rate\n",
    "                optimizer.step()\n",
    "                scheduler.step()\n",
    "\n",
    "                # Print the loss values and time elapsed for every 20 batches\n",
    "                if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
    "                    # Calculate time elapsed for 20 batches\n",
    "                    time_elapsed = time.time() - t0_batch\n",
    "\n",
    "                    # Print training results\n",
    "                    if debug: print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
    "\n",
    "                    # Reset batch tracking variables\n",
    "                    batch_loss, batch_counts = 0, 0\n",
    "                    t0_batch = time.time()\n",
    "\n",
    "            # Calculate the average loss over the entire training data\n",
    "            avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "            if debug: print(\"-\"*70)\n",
    "            # =======================================\n",
    "            #               Evaluation\n",
    "            # =======================================\n",
    "            if evaluation == True:\n",
    "                # After the completion of each training epoch, measure the model's performance\n",
    "                # on our validation set.\n",
    "                val_loss, val_accuracy = evaluate(model, val_dataloader, device)\n",
    "\n",
    "                # Print performance over the entire training data\n",
    "                time_elapsed = time.time() - t0_epoch\n",
    "\n",
    "                if debug: print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
    "                if debug: print(\"-\"*70)\n",
    "            if debug: print(\"\\n\")\n",
    "        if debug: print(\"Training complete!\")\n",
    "\n",
    "    \n",
    "    all_preds = []\n",
    "    full_preds = {}\n",
    "    \n",
    "    for art, df_train in tqdm(df_train_sets.items()):\n",
    "        \n",
    "        if type(df_train) == str:\n",
    "            df_train = pd.read_csv(df_train).dropna()\n",
    "        \n",
    "        # Balance the training data\n",
    "        df_train = balance_dataset(df_train) \n",
    "\n",
    "        # Split the features and label\n",
    "        X_train = df_train['text'].to_numpy()\n",
    "        y_train = df_train['violation'].to_numpy()\n",
    "        X_test = df_test['text'].to_numpy()\n",
    "        y_test = df_test['violation'].to_numpy()\n",
    "\n",
    "        # Preprocess\n",
    "        tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "        train_inputs, train_masks = preprocessing_for_bert(X_train, tokenizer)\n",
    "        set_seed(42)\n",
    "     \n",
    "        # Train\n",
    "        train_labels = torch.tensor(y_train)\n",
    "        train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "        train_sampler = RandomSampler(train_data)\n",
    "        train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "        bert_classifier, optimizer, scheduler = initialize_model(device, train_dataloader, epochs=epochs)\n",
    "        train(bert_classifier, train_dataloader, epochs=epochs)\n",
    "\n",
    "        # Test\n",
    "        test_inputs, test_masks = preprocessing_for_bert(X_test, tokenizer)\n",
    "        test_dataset = TensorDataset(test_inputs, test_masks)\n",
    "        test_sampler = SequentialSampler(test_dataset)\n",
    "        test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=batch_size)\n",
    "        probs = bert_predict(bert_classifier, test_dataloader)\n",
    "\n",
    "        # Get predictions from the probabilities\n",
    "        threshold = 0.5\n",
    "        preds = np.where(probs[:, 1] >= 0.5, 1, 0)\n",
    "        full_preds[art] = preds\n",
    "        \n",
    "        # OR layer: if any model predicts violation the ensemble prediction is violation\n",
    "        if len(all_preds) == 0:\n",
    "            all_preds = preds\n",
    "        else:\n",
    "            for idx, pred in enumerate(preds):\n",
    "                all_preds[idx] = max(pred, all_preds[idx])\n",
    "        gc.collect()\n",
    "\n",
    "        \n",
    "    full_preds['final_pred'] = all_preds\n",
    "    full_preds['true_pred'] = y_test\n",
    "    \n",
    "        \n",
    "    return return_metrics(all_preds, y_test), pd.DataFrame.from_dict(full_preds) #acc, mcc, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "653b0ddc-dc1c-4b61-aa98-b2a0206d2a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 1995\n",
    "random_states = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "def generate_ensemble_dataset(path, random_state, write=False):\n",
    "\n",
    "    article_numbers = ['2', '3', '5', '6', '8', '10', '11', '13', '14']\n",
    "    datasets = {art: create_dataset(path, art, part) for art in tqdm(article_numbers)}\n",
    "    df_all = create_dataset(json_path, 'All', part)\n",
    "\n",
    "    # Individual training datasets (for each article)\n",
    "    train_dbs = {}\n",
    "    \n",
    "    # Individual training datasets including irrelevant cases (with non-violation label for that case)\n",
    "    improved_train_dbs = {}\n",
    "    \n",
    "    # General test dataset (binary)\n",
    "    test_db = [] \n",
    "    test_size = 0.1\n",
    "\n",
    "    # Remove 10% of all the datasets\n",
    "    for art, db in datasets.items():\n",
    "        db['article'] = art\n",
    "        train, test = train_test_split(db, test_size=0.1, random_state=random_state, stratify=db['violation'])\n",
    "        train_dbs[art] = train \n",
    "        test_db.append(test)\n",
    "\n",
    "    # All individual 10% test cases form the big test dataset\n",
    "    test_db = pd.concat(test_db)\n",
    "\n",
    "    # The general test set has binary labels\n",
    "    test_general = df_all[df_all.id.isin(test_db['id'])]\n",
    "\n",
    "    # General training dataset (binary)\n",
    "    # Remove all test instances from the general training dataset\n",
    "    train_general = df_all[~df_all.id.isin(test_db['id'])]\n",
    "    \n",
    "    # improved ensemble datasets\n",
    "    for art, db in train_dbs.items():\n",
    "        \n",
    "        # All cases that were not in the article db\n",
    "        additional_cases = df_all[~df_all.id.isin(db['id'])]\n",
    "        additional_cases['violation'] = 0\n",
    "        additional_cases['article'] = 999 # add 999 to symbolise that it is another article\n",
    "        \n",
    "        # split violation and non violation of the article db\n",
    "        violation_cases = db[db['violation']==1]\n",
    "        nonviolation_cases = db[db['violation']==0]\n",
    "        violation_cases = violation_cases.sample(n=min(2500, len(violation_cases))) # take a sample to reduce space\n",
    "               \n",
    "        # There are usually less nonviolation cases. Add additional cases from other articles such that the number of non-violation cases\n",
    "        # is equal to the amount of violation cases, making a larger, balanced dataset. If there are more non-violation cases, add nothing.\n",
    "        additional_cases = additional_cases.sample(n=max(0, len(violation_cases)-len(nonviolation_cases)))\n",
    "        \n",
    "        # Add the three datasets together\n",
    "        improved_train_dbs[art] = pd.concat([violation_cases, nonviolation_cases, additional_cases])\n",
    "        \n",
    "        if debug: print(art, len(db), len(violation_cases),  len(nonviolation_cases), len(additional_cases), len(improved_train_dbs[art]))\n",
    "        del additional_cases\n",
    "        del violation_cases\n",
    "        del nonviolation_cases\n",
    "        \n",
    "    # Write all datasets to csv to reduce memory\n",
    "    if write:\n",
    "        balance_dataset(train_general).to_csv('results/ensemble/temp/train_general.csv')\n",
    "        test_general.to_csv('results/ensemble/temp/test_general.csv')\n",
    "\n",
    "        for art, db in train_dbs.items():\n",
    "            balance_dataset(db).to_csv('results/ensemble/temp/train_dbs'+str(art)+'.csv')\n",
    "\n",
    "        for art, db in improved_train_dbs.items():\n",
    "            balance_dataset(db).to_csv('results/ensemble/temp/improved_train_dbs'+str(art)+'.csv')\n",
    "\n",
    "        del train_dbs\n",
    "        del improved_train_dbs\n",
    "        del train_general\n",
    "        del test_general\n",
    "        gc.collect()\n",
    "\n",
    "        return None, None, None, None\n",
    "    \n",
    "    return train_dbs, improved_train_dbs, train_general, test_general\n",
    "\n",
    "def read_ensemble_dataset(db_name):\n",
    "    if db_name == 'train_general':\n",
    "        return pd.read_csv('results/ensemble/temp/train_general.csv').dropna()\n",
    "    if db_name == 'test_general':\n",
    "        return pd.read_csv('results/ensemble/temp/test_general.csv').dropna()\n",
    "    if db_name == 'train_dbs':\n",
    "        return {art:'results/ensemble/temp/train_dbs'+str(art)+'.csv'\n",
    "                for art in ['2', '3', '5', '6', '8', '10', '11', '13', '14']}\n",
    "    if db_name == 'improved_train_dbs':\n",
    "        return {art:'results/ensemble/temp/improved_train_dbs'+str(art)+'.csv'\n",
    "                for art in ['2', '3', '5', '6', '8', '10', '11', '13', '14']}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ef4aa56-d176-4aad-b407-4843802ed972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(model, model_name, random_state, provided_dbs=None):\n",
    "    if not provided_dbs:\n",
    "        print('\\tNo provided data, reading from files')\n",
    "        train_dbs, improved_train_dbs, train_general, test_general = generate_ensemble_dataset(json_path, random_state)\n",
    "        train_dbs, improved_train_dbs, train_general, test_general = read_ensemble_dataset()\n",
    "    else:\n",
    "        train_dbs = provided_dbs['train_dbs']\n",
    "        improved_train_dbs = provided_dbs['improved_train_dbs']\n",
    "        train_general = provided_dbs['train_general']\n",
    "        test_general = provided_dbs['test_general']\n",
    "        \n",
    "    # Set 'unknown' as default value\n",
    "    acc_g = mcc_g = f1_g = acc_e = mcc_e = f1_e = acc_e2 = mcc_e2 = f1_e2 = -999\n",
    "\n",
    "    # General\n",
    "    print('\\tTraining general classifier')\n",
    "    (acc_g, mcc_g, f1_g), full_preds = train_test(model, read_ensemble_dataset('train_general'), read_ensemble_dataset('test_general'))\n",
    "    full_preds.to_csv('results/ensemble/full_preds/'+model_name+'/general/full_preds_general_'+str(random_state)+'.csv')\n",
    "\n",
    "    #ensemble\n",
    "    print('\\tTraining ensemble')\n",
    "    (acc_e, mcc_e, f1_e), full_preds = train_test_ensemble(model, read_ensemble_dataset('train_dbs'), read_ensemble_dataset('test_general'))\n",
    "    full_preds.to_csv('results/ensemble/full_preds/'+model_name+'/ensemble/full_preds_ensemble_'+str(random_state)+'.csv')\n",
    "    \n",
    "    #improved ensemble\n",
    "    print('\\tTraining improved ensemble')\n",
    "    (acc_e2, mcc_e2, f1_e2), full_preds = train_test_ensemble(model, read_ensemble_dataset('improved_train_dbs'), read_ensemble_dataset('test_general'))\n",
    "    full_preds.to_csv('results/ensemble/full_preds/'+model_name+'/improved_ensemble/full_preds_improved_ensemble_'+str(random_state)+'.csv')\n",
    "    \n",
    "    print('\\tWriting data')\n",
    "    field_names = ['model', 'random_state', 'accuracy_general', 'MCC_general', 'F1_general', \n",
    "                   'accuracy_ensemble', 'MCC_ensemble', 'F1_ensemble', \n",
    "                   'accuracy_improved_ensemble', 'MCC_improved_ensemble', 'F1_improved_ensemble', \n",
    "                   'alpha',  'training_size', 'test_size', 'train_distribution', 'test_distribution']\n",
    "    \n",
    "    \n",
    "    train_general = read_ensemble_dataset('train_general')\n",
    "    test_general = read_ensemble_dataset('test_general')\n",
    "    \n",
    "    dct = {\n",
    "        'model': model_name,\n",
    "        'random_state': random_state,\n",
    "        'accuracy_general': acc_g,\n",
    "        'MCC_general': mcc_g,\n",
    "        'F1_general': f1_g,\n",
    "        'accuracy_ensemble': acc_e,\n",
    "        'MCC_ensemble': mcc_e,\n",
    "        'F1_ensemble': f1_e,\n",
    "        'accuracy_improved_ensemble': acc_e2,\n",
    "        'MCC_improved_ensemble': mcc_e2,\n",
    "        'F1_improved_ensemble': f1_e2,\n",
    "        'alpha': best_alpha,\n",
    "        'training_size': len(train_general),\n",
    "        'test_size': len(test_general),\n",
    "        'train_distribution': round(train_general['violation'].mean()*100,2),\n",
    "        'test_distribution': round(test_general['violation'].mean()*100,2)\n",
    "         }\n",
    "    \n",
    "    filename = 'results/ensemble/ensemble_general_bert.csv'\n",
    "    file_exists = os.path.isfile(filename)\n",
    "    with open(filename, 'a') as f_object:\n",
    "        dictwriter_object = DictWriter(f_object, fieldnames=field_names)\n",
    "        if not file_exists:\n",
    "            dictwriter_object.writeheader()  # file doesn't exist yet, write a header\n",
    "        dictwriter_object.writerow(dct)\n",
    "        f_object.close()\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e16c80-2e0e-4d16-9909-7682abc4d5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "provided_dbs = None\n",
    "debug = False\n",
    "for random_state in [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]:\n",
    "    print('Random_state:', random_state)\n",
    "    _, _, _, _ = generate_ensemble_dataset(json_path, random_state, write=True)\n",
    "\n",
    "    print('BERT')\n",
    "    run_experiment(None, 'BERT', random_state, provided_dbs=provided_dbs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
